{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ba06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/ajinkyamawal/Review-Sentiment-Classifier/capterra_reviews.csv\")\n",
    "\n",
    "# Create a binary label: 1 if rating >= 4, else 0\n",
    "df['label'] = (df['overall_rating'] >= 4).astype(int)\n",
    "\n",
    "# Keep only text and label columns\n",
    "df = df[['overall_text', 'label']].rename(columns={'review': 'text'})\n",
    "df = df.dropna()\n",
    "\n",
    "df.to_csv('capterra_reviews_binary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53a405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('capterra_reviews_binary.csv')\n",
    "train, temp = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, stratify=temp['label'], random_state=42)\n",
    "\n",
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d871ed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.32.5)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Using cached huggingface_hub-1.3.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /Users/ajinkyamawal/Library/Python/3.13/lib/python/site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions>=4.1.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ajinkyamawal/Library/Python/3.13/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ajinkyamawal/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached huggingface_hub-1.3.1-py3-none-any.whl (533 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Using cached aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl (490 kB)\n",
      "Using cached multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, typing-extensions, tqdm, shellingham, pyyaml, pyarrow, propcache, multidict, hf-xet, h11, fsspec, frozenlist, filelock, dill, click, attrs, anyio, aiohappyeyeballs, yarl, typer-slim, multiprocess, httpcore, aiosignal, httpx, aiohttp, huggingface-hub, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [datasets]/27\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 attrs-25.4.0 click-8.3.1 datasets-4.4.2 dill-0.4.0 filelock-3.20.3 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.3.1 multidict-6.7.0 multiprocess-0.70.18 propcache-0.4.1 pyarrow-22.0.0 pyyaml-6.0.3 shellingham-1.5.4 tqdm-4.67.1 typer-slim-0.21.1 typing-extensions-4.15.0 xxhash-3.6.0 yarl-1.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04392baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 3881 examples [00:00, 414411.76 examples/s]\n",
      "Generating validation split: 485 examples [00:00, 206040.46 examples/s]\n",
      "Generating test split: 486 examples [00:00, 163152.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"validation\": \"val.csv\",\n",
    "    \"test\": \"test.csv\",\n",
    "}\n",
    "datasets = load_dataset(\"csv\", data_files=data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b453814",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.bert.named_parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized_datasets = datasets.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1652d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "roc_auc = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = np.exp(logits) / np.exp(logits).sum(-1, keepdims=True)\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    auc = roc_auc.compute(prediction_scores=probs[:, 1], references=labels)[\"roc_auc\"]\n",
    "    acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    return {\"accuracy\": acc, \"roc_auc\": auc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert-review-sentiment\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"roc_auc\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f499e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6343029",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv1)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
